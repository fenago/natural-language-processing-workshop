{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import download\n",
    "download('stopwords')\n",
    "download('wordnet')\n",
    "download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import stem, pos_tag\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the text file into variable called sentence\n",
    "sentence = open(\"../data/file.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(lang='en')\n",
    "\n",
    "def correct_sentence(words):\n",
    "    corrected_sentence = \"\"\n",
    "    corrected_word_list = []\n",
    "    for wd in words:\n",
    "        if wd not in string.punctuation:\n",
    "            wd_c = spell(wd)\n",
    "            if wd_c != wd:\n",
    "                print(wd+\" has been corrected to: \"+wd_c)\n",
    "                corrected_sentence = corrected_sentence+\" \"+wd_c\n",
    "                corrected_word_list.append(wd_c)\n",
    "            else:\n",
    "                corrected_sentence = corrected_sentence+\" \"+wd\n",
    "                corrected_word_list.append(wd)\n",
    "        else:\n",
    "            corrected_sentence = corrected_sentence + wd\n",
    "            corrected_word_list.append(wd)\n",
    "    return corrected_sentence, corrected_word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_sentence, corrected_word_list = correct_sentence(words)\n",
    "# lenguage has been corrected to: language\n",
    "# knowldge has been corrected to: knowledge\n",
    "# Familiarity has been corrected to: familiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"\"\"The reader of this course should have a basic knowledge of the Python programming language. He/she must have knowledge of data types in Python. He should be able to write functions,and also have the ability to import and use libraries and packages in Python. familiarity with basic linguistics and probability is assumed although not required to fully complete this course\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_sentence  = c\n",
    "corrected_word_list = word_tokenize(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrected_word_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_tag(corrected_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def remove_stop_words(word_list):\n",
    "    corrected_word_list_without_stopwords = []\n",
    "    for wd in word_list:\n",
    "        if wd not in stop_words:\n",
    "            corrected_word_list_without_stopwords.append(wd)\n",
    "    return corrected_word_list_without_stopwords\n",
    "\n",
    "corrected_word_list_without_stopwords = remove_stop_words(corrected_word_list)\n",
    "corrected_word_list_without_stopwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = stem.PorterStemmer()\n",
    "def get_stems(word_list):\n",
    "    corrected_word_list_without_stopwords_stemmed = []\n",
    "    for wd in word_list:\n",
    "        corrected_word_list_without_stopwords_stemmed.append(stemmer.stem(wd))\n",
    "    return corrected_word_list_without_stopwords_stemmed\n",
    "\n",
    "corrected_word_list_without_stopwords_stemmed = get_stems(corrected_word_list_without_stopwords)\n",
    "corrected_word_list_without_stopwords_stemmed[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_lemma(word_list):\n",
    "    corrected_word_list_without_stopwords_lemmatized = []\n",
    "    for wd in word_list:\n",
    "        corrected_word_list_without_stopwords_lemmatized.append(lemmatizer.lemmatize(wd))\n",
    "    return corrected_word_list_without_stopwords_lemmatized\n",
    "corrected_word_list_without_stopwords_lemmatized =  get_lemma(corrected_word_list_without_stopwords_stemmed)\n",
    "corrected_word_list_without_stopwords_lemmatized[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent_tokenize(corrected_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
